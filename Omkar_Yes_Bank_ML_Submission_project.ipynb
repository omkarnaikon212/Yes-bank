{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarnaikon212/Yes-bank/blob/main/Omkar_Yes_Bank_ML_Submission_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - YES_BANK/EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Team Member 1 -** OMKAR NAIK\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/omkarnaikon212"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PROBLEM STATEMENT :-**\n",
        "\n",
        "### Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month.\n",
        "\n",
        "\n",
        "\n",
        "### ***Our main objective is to predict the stockâ€™s closing price of the month.*** \n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## . Know Your Data"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1OxxHhA11hXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/data_YesBank_StockPrices.csv')\n",
        "df = pd.DataFrame(df, columns=['Date', 'Open', 'High', 'Low', 'Close'])\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head "
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import missingno as msno\n",
        "msno.matrix(df)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What did you know about your dataset?\n",
        "No missing value in dataset "
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us now preserve the original data before we operate on it.\n",
        "preserved_stock_data = df.copy()"
      ],
      "metadata": {
        "id": "dWj-QzLaBvWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description\n",
        " "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date :- The date (Month and Year provided)\n",
        "\n",
        "\n",
        "Open :- The price of the stock at the beginning of a particular time period.\n",
        "\n",
        "High :-The Peak(Maximum) price at which a stock traded during the period.\n",
        "\n",
        "Low :-The Lowest price at which a stock traded during the period.\n",
        "\n",
        "Close :- The trading price at the end (in this case end of the month).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df['Date'].unique\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Open'].unique"
      ],
      "metadata": {
        "id": "jv9pqj7xBGlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['High'].unique"
      ],
      "metadata": {
        "id": "E01dLPWiBGp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Low'].unique"
      ],
      "metadata": {
        "id": "2Ir8utKsBG9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35PGjQyWJfQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Close'].unique"
      ],
      "metadata": {
        "id": "W4NvIrIEBPTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to modify this before passing it to a model.\n",
        "# lets convert Date column to a proper datetime datatype.\n",
        "from datetime import datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'].apply(lambda x: datetime.strptime(x, '%b-%y')))     # this converts date to a yyyy-mm-dd format.\n"
      ],
      "metadata": {
        "id": "9wr4rA_AIhdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head"
      ],
      "metadata": {
        "id": "bkqow7u6JbNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "V6mN2sJ3JgKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index('Date', inplace=True)      "
      ],
      "metadata": {
        "id": "eOPIm_4NJs4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KTofq5LCIo8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "for col in df.columns:\n",
        "  plt.figure(figsize=(7,5))\n",
        "  sns.boxplot(df[col])\n",
        "  plt.xlabel(col, fontsize=13)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see there are someoutlier in present in data. "
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EDA**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating the  two part dependent variabels and independent variables.\n",
        "independent_variables = df.columns.tolist()[:-1]\n",
        "dependent_variable = ['Close']\n",
        "\n",
        "print(independent_variables)\n",
        "print(dependent_variable)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ploting dependent variable \n",
        "plt.figure(figsize=(12,7))\n",
        "df['Close'].plot(color = \"r\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.title('Closing Price with Date')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BQsX9r2NLZTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the stock price is rising up untill 2018.\n",
        "\n",
        "when the fraud case involving rana kapoor then after stock price are sharp decline."
      ],
      "metadata": {
        "id": "NCA3Ip4mMck_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the distributions of all features.\n",
        "for col in df.columns:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.distplot(df[col], color='y')\n",
        "  plt.xlabel(col, fontsize=13)\n",
        "  plt.ylabel('count')\n",
        "\n",
        "  # Plotting the mean and the median.\n",
        "  plt.axvline(df[col].mean(),color='green',linewidth=2)                            # axvline plots a vertical line at a value (mean in this case). \n",
        "  plt.axvline(df[col].median(),color='red',linestyle='dashed',linewidth=1.5)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "mNP4qCIgQw4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that these distributions are positively skewed. The mean and median are at significant distance from each other.\n",
        "\n",
        "So we need to transform them into something close to a Normal Distribution as our models give optimal results that way."
      ],
      "metadata": {
        "id": "eRoxO69IRD3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "for col in df.columns:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.distplot(np.log10(df[col]), color='y')\n",
        "  plt.xlabel(col, fontsize=13)\n",
        "  plt.ylabel('count')\n",
        "\n",
        "  # Plotting the mean and the median.\n",
        "  plt.axvline(np.log10(df[col]).mean(),color='green',linewidth=2)                            # axvline plots a vertical line at a value (mean in this case). \n",
        "  plt.axvline(np.log10(df[col]).median(),color='red',linestyle='dashed',linewidth=1.5)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the distributions are very similar to Normal distribution. The mean and median values are nearly same."
      ],
      "metadata": {
        "id": "ZmELXtwKSW98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check for outliers now in the transformed variable data.\n",
        "for col in df.columns:\n",
        "  plt.figure(figsize=(7,7))\n",
        "  sns.boxplot(np.log10(df[col]))\n",
        "  plt.xlabel(col, fontsize=13)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have no outliers anymore. Log transformation diminishes the outlier's effect."
      ],
      "metadata": {
        "id": "JEZlA_H_TBz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visualise for the correlation among all variables.\n",
        "corr = df.corr()\n",
        "plt.figure(figsize=(16,7))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open price & High price Or low price & closing price they are highly co-related.\n"
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Let's visualise the relationship between each pair of variables using pair plots.\n",
        "sns.pairplot(df)"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing**\n"
      ],
      "metadata": {
        "id": "PgaJ55nQqCdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dealing with multicollinearity using VIF analysis.\n",
        "# Calculating VIF(Variation Inflation Factor) to see the correlation between independent variables\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor  \n",
        "\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "vUWUJqtMqCrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Date','Close']]])"
      ],
      "metadata": {
        "id": "ArEid2meqIUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Feature Engineering**"
      ],
      "metadata": {
        "id": "-pYTwuZ3Wfp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Split \n",
        "# Creating arrays of our input variable and label to feed the data to the model.\n",
        "# Create the data of independent variables\n",
        "            # applying log transform on our independent variables.\n",
        "x = np.log10(df[independent_variables]).values\n",
        "# Create the dependent variable data\n",
        "y = np.log10(df[dependent_variable]).values               # applying log transform on our dependent variable.\n"
      ],
      "metadata": {
        "id": "xF4-Cl9AdGZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state= 0)"
      ],
      "metadata": {
        "id": "cX_5Wyg_dqg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Standardization** "
      ],
      "metadata": {
        "id": "4kUw-shigIyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "8MYmIvVXgeED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "x_train =scaler.fit_transform(x_train)\n",
        "x_test  =scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "PYaB9UYOgvSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0:10]"
      ],
      "metadata": {
        "id": "wrQAVnwcizRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model traning**"
      ],
      "metadata": {
        "id": "GIHuPn3SW67R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**1.Linear Regression**"
      ],
      "metadata": {
        "id": "5-s1sEOTi_DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries from linear regression model and metrics \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "mQqy6X5_i2Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initializing the model.\n",
        "lr = LinearRegression()"
      ],
      "metadata": {
        "id": "MUwUav6pguRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting on our traing data.\n",
        "lr.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "skj4ahEudpp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on our test data.\n",
        "y_pred_linear = lr.predict(x_test)"
      ],
      "metadata": {
        "id": "SGnwpYwxk1bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the model coefficients\n",
        "lr.coef_"
      ],
      "metadata": {
        "id": "o9xHJ-tZk1nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the model parameters. printing the intercept.\n",
        "lr.intercept_"
      ],
      "metadata": {
        "id": "OHDE9Cwck1ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAE_linear = round(mean_absolute_error(10**(y_test),(10**y_pred_linear)),4)\n",
        "print(f\"Mean Absolute Error : {MAE_linear}\")\n",
        "\n",
        "MSE_linear = round(mean_squared_error((10**y_test),10**(y_pred_linear)),4)\n",
        "print(f\"Mean squared Error : {MSE_linear}\")\n",
        "\n",
        "RMSE_linear = round(np.sqrt(MSE_linear),4)\n",
        "print(f\"Root Mean squared Error : {RMSE_linear}\")\n",
        "\n",
        "R2_linear = round(r2_score(10**(y_test), 10**(y_pred_linear)),4)\n",
        "print(f\"R2 score : {R2_linear}\")\n",
        "\n",
        "Adjusted_R2_linear = round(1-(1-r2_score(10**y_test,10**y_pred_linear))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)),3)\n",
        "print(f\"Adjusted R2 score : {Adjusted_R2_linear}\")"
      ],
      "metadata": {
        "id": "VrpvEzsAwQ-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the actual and predicted test data.\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(10**y_pred_linear)\n",
        "plt.plot(np.array(10**y_pred_linear))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Actual vs Predicted Closing price Linear regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3PQilC_tsaee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to store our performance data for this model so that we can compare them with other models. Let's store them in a dict for now."
      ],
      "metadata": {
        "id": "lpZry43Hw2uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regessor_list = {'Mean Absolute Error' : MAE_linear,'Mean squared Error' : MSE_linear,\n",
        "                   'Root Mean squared Error' : RMSE_linear,'R2 score' : R2_linear,'Adjusted R2 score' : Adjusted_R2_linear }"
      ],
      "metadata": {
        "id": "s9msuja4xSf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting above dict into a dataframe\n",
        "metric_df = pd.DataFrame.from_dict(linear_regessor_list, orient='index').reset_index()"
      ],
      "metadata": {
        "id": "1CGbC9EKw27_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming the columns.\n",
        "metric_df = metric_df.rename(columns={'index':'Metric',0:'Linear Regression'})\n",
        "metric_df"
      ],
      "metadata": {
        "id": "fyZlP_mGw240"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Lasso Regression** with cross validated regularization.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "729KpE-Cxd_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Lasso model.\n",
        "from sklearn.linear_model import Lasso"
      ],
      "metadata": {
        "id": "OqsYFW3Xxz8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the model with some base values.\n",
        "lasso  = Lasso(alpha=0.0001 , max_iter= 3000)\n",
        "# Fitting the model on our training data.\n",
        "lasso.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "gn2CT8eJxz_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the intercept and coefficients.\n",
        "lasso.intercept_"
      ],
      "metadata": {
        "id": "7aagXrpCx0DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.coef_"
      ],
      "metadata": {
        "id": "qvtSOG4qx0GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation. optimizing our model by finding the best value of our hyperparameter.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "lasso_param_grid = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,0.005,0.006,0.007,0.01,0.015,0.02,1e-1,1,5,10,20,30,40,45,50]}  # list of parameters. \n",
        "                                                                                  \n",
        "lasso_regressor = GridSearchCV(lasso, lasso_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_regressor.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "kE0rCiOux0Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the best parameter\n",
        "lasso_regressor.best_params_     "
      ],
      "metadata": {
        "id": "wIl_N2cryIOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the best score\n",
        "lasso_regressor.best_score_"
      ],
      "metadata": {
        "id": "4wrd2WOwyIR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the test dataset.\n",
        "y_pred_lasso = lasso_regressor.predict(x_test)\n",
        "print(y_pred_lasso)"
      ],
      "metadata": {
        "id": "QNNE3nFnyIVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the performance using evaluation metrics.\n",
        "MAE_lasso = round(mean_absolute_error(10**(y_test),10**(y_pred_lasso)),4)\n",
        "print(f\"Mean Absolute Error : {MAE_lasso}\")\n",
        "\n",
        "MSE_lasso  = round(mean_squared_error(10**(y_test),10**(y_pred_lasso)),4)\n",
        "print(\"Mean squared Error :\" , MSE_lasso)\n",
        "\n",
        "RMSE_lasso = round(np.sqrt(MSE_lasso),4)\n",
        "print(\"Root Mean squared Error :\" ,RMSE_lasso)\n",
        "\n",
        "R2_lasso = round(r2_score(10**(y_test), 10**(y_pred_lasso)),4)\n",
        "print(\"R2 score :\" ,R2_lasso)\n",
        "\n",
        "Adjusted_R2_lasso = round(1-(1-r2_score(10**y_test, 10**y_pred_lasso))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)),4)\n",
        "print(\"Adjusted R2 score: \", Adjusted_R2_lasso)"
      ],
      "metadata": {
        "id": "HjTJeNTtyIbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now saving these metrics to our metrics dataframe. First we save them in a list and then we pass them to the df.\n",
        "metric_df['Lasso'] = [MAE_lasso, MSE_lasso, RMSE_lasso, R2_lasso, Adjusted_R2_lasso]"
      ],
      "metadata": {
        "id": "o-AB-MsmyIfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the predicted values vs actual.\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(10**y_pred_lasso)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Actual vs Predicted Closing price Lasso regression\")"
      ],
      "metadata": {
        "id": "5Ck8Zhyaypia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_regessor_list = {'Mean Absolute Error' : MAE_linear,'Mean squared Error' : MSE_linear,\n",
        "                   'Root Mean squared Error' : RMSE_linear,'R2 score' : R2_linear,'Adjusted R2 score' : Adjusted_R2_linear }"
      ],
      "metadata": {
        "id": "26m4mMIAy0ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_df_lasso = pd.DataFrame.from_dict(lasso_regessor_list, orient='index').reset_index()"
      ],
      "metadata": {
        "id": "qTcjC0_ay9Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming the columns.\n",
        "metric_df_lasso = metric_df.rename(columns={'index':'Metric',0:'lasso regressor'})\n",
        "metric_df_lasso"
      ],
      "metadata": {
        "id": "O-seZ7fLy9a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now use this df to store all metrics of all other models so we can easily compare them."
      ],
      "metadata": {
        "id": "c3I6pgjxzWgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Ridge Regression** with cross validated regularization.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "y4uY9_gJxipg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing ridge regressor model.\n",
        "from sklearn.linear_model import Ridge    \n",
        "ridge = Ridge()         # iitializing the model\n",
        "\n",
        "# initiating the parameter grid for alpha (regularization strength).\n",
        "ridge_param_grid = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,0.3,0.7,1,1.2,1.33,1.365,1.37,1.375,1.4,1.5,1.6,1.8,2.5,5,10,20,30,40,45,50,55,60,100]}\n",
        "\n",
        "# cross validation. \n",
        "ridge_regressor = GridSearchCV(ridge, ridge_param_grid, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "Q9ku1MeXyBRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the best parameter value (for alpha)\n",
        "ridge_regressor.best_params_"
      ],
      "metadata": {
        "id": "aDRXkeg4yBVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the best score for optimal value of alpha.\n",
        "ridge_regressor.best_score_"
      ],
      "metadata": {
        "id": "of-4sJclzduL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting on the test dataset now.\n",
        "y_pred_ridge = ridge_regressor.predict(x_test)"
      ],
      "metadata": {
        "id": "jTvksLpfzdxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAE_ridge = round(mean_absolute_error(10**(y_test),10**(y_pred_ridge)),4)\n",
        "print(f\"Mean Absolute Error : {MAE_ridge}\")\n",
        "\n",
        "MSE_ridge  = round(mean_squared_error(10**(y_test),10**(y_pred_ridge)),4)\n",
        "print(\"Mean squared Error :\" , MSE_ridge)\n",
        "\n",
        "RMSE_ridge = round(np.sqrt(MSE_ridge),4)\n",
        "print(\"Root Mean squared Error :\" ,RMSE_ridge)\n",
        "\n",
        "R2_ridge = round(r2_score(10**(y_test), 10**(y_pred_ridge)),4)\n",
        "print(\"R2 score :\" ,R2_ridge)\n",
        "\n",
        "Adjusted_R2_ridge = round(1-(1-r2_score(10**y_test, 10**y_pred_ridge))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)),4)\n",
        "print(\"Adjusted R2 score: \", Adjusted_R2_ridge)"
      ],
      "metadata": {
        "id": "LrMDDXawzd2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing these values in a list and appending to our metric df.\n",
        "ridge_regressor_list = [MAE_ridge,MSE_ridge,RMSE_ridge,R2_ridge,Adjusted_R2_ridge]\n",
        "metric_df['Ridge'] = ridge_regressor_list"
      ],
      "metadata": {
        "id": "tEseCpZ7zd5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_regessor_list = {'Mean Absolute Error' : MAE_linear,'Mean squared Error' : MSE_linear,\n",
        "                   'Root Mean squared Error' : RMSE_linear,'R2 score' : R2_linear,'Adjusted R2 score' : Adjusted_R2_linear }"
      ],
      "metadata": {
        "id": "VFSbMW85yBY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting above dict into a dataframe\n",
        "metric_df_ridge = pd.DataFrame.from_dict(linear_regessor_list, orient='index').reset_index()"
      ],
      "metadata": {
        "id": "zxCVKRXA0Gwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming the columns.\n",
        "metric_df_ridge = metric_df.rename(columns={'index':'Metric',0:'Ridge Regression'})\n",
        "metric_df_ridge"
      ],
      "metadata": {
        "id": "e0dxCG8p0G8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. **Elastic-Net Regression** with cross validation."
      ],
      "metadata": {
        "id": "04G7Gtcm1O1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing and initializing Elastic-Net Regression.\n",
        "from sklearn.linear_model import ElasticNet\n",
        "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n"
      ],
      "metadata": {
        "id": "rhyUBib71h_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing parameter grid.\n",
        "elastic_net_param_grid = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,0.001,0.01,0.02,0.03,0.04,1,5,10,20,40,50,60,100],\n",
        "                          'l1_ratio':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}\n",
        "\n",
        "# cross-validation.\n",
        "elasticnet_regressor = GridSearchCV(elasticnet_model, elastic_net_param_grid, scoring='neg_mean_squared_error',cv=5)\n",
        "elasticnet_regressor.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "z7X9Dw971iDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the best parameter\n",
        "elasticnet_regressor.best_params_"
      ],
      "metadata": {
        "id": "id8R84ll1iHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the best score for the optimal parameter.\n",
        "elasticnet_regressor.best_score_"
      ],
      "metadata": {
        "id": "4aiisRqr1iKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making the predictions.\n",
        "y_pred_elastic_net = elasticnet_regressor.predict(x_test)"
      ],
      "metadata": {
        "id": "Grcbhmg-1iOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAE_elastic_net = round(mean_absolute_error(10**(y_test),10**(y_pred_elastic_net)),4)\n",
        "print(f\"Mean Absolute Error : {MAE_elastic_net}\")\n",
        "\n",
        "MSE_elastic_net  = round(mean_squared_error(10**(y_test),10**(y_pred_elastic_net)),4)\n",
        "print(\"Mean squared Error :\" , MSE_elastic_net)\n",
        "\n",
        "RMSE_elastic_net = round(np.sqrt(MSE_elastic_net),4)\n",
        "print(\"Root Mean squared Error :\" ,RMSE_elastic_net)\n",
        "\n",
        "R2_elastic_net = round(r2_score(10**(y_test), (10**y_pred_elastic_net)),4)\n",
        "print(\"R2 score :\" ,R2_elastic_net)\n",
        "\n",
        "Adjusted_R2_elastic_net = round(1-(1-r2_score(10**y_test, 10**y_pred_elastic_net))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1)),4)\n",
        "print(\"Adjusted R2 score: \", Adjusted_R2_elastic_net)"
      ],
      "metadata": {
        "id": "ikwtd_aH3K9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing these metrics in our dataframe.\n",
        "elastic_net_metric_list = [MAE_elastic_net,MSE_elastic_net,RMSE_elastic_net,R2_elastic_net,Adjusted_R2_elastic_net]\n",
        "metric_df['Elastic Net'] = elastic_net_metric_list"
      ],
      "metadata": {
        "id": "cKAY3CSm3LAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us plot the actual and predicted target variables values.\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(10**y_pred_elastic_net)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Actual vs Predicted Closing price Elastic Net regression\")"
      ],
      "metadata": {
        "id": "15EEgf533Uy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparing the performance of all models that we have implemented.\n",
        "metric_df"
      ],
      "metadata": {
        "id": "oOFL1uYZ3ZHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Actual vs Predicted Closing Price values by various Algorithms"
      ],
      "metadata": {
        "id": "xL3wetYu0HX1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtZ_mdWC3KPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the predicted values of all the models against the true values.\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.plot(10**y_test, linewidth=2)\n",
        "plt.plot(10**y_pred_elastic_net)\n",
        "plt.plot(10**y_pred_linear)\n",
        "plt.plot(10**y_pred_lasso)\n",
        "plt.plot(10**y_pred_ridge)\n",
        "\n",
        "plt.legend(['linear','lasso','ridge','elastic_net'])\n",
        "plt.title('Actual vs Predicted Closing Price values by various Algorithms', weight = 'bold',fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wESWVQqT06ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from above graph, all of our models are performing really well and are able to closely approximate the actual values."
      ],
      "metadata": {
        "id": "afmpli7q33by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the actual and elastic net predicted target variables values in a dataframe. \n",
        "actual_pred_df = pd.DataFrame(10**y_test,10**y_pred_elastic_net).reset_index().rename(columns = {'index':'Actual values',0:'Elastic Net Predicted values'})\n",
        "actual_pred_df.head()"
      ],
      "metadata": {
        "id": "w7EgqrHp4JQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Using data visualization on our target variable, we can clearly see the impact of 2018 fraud case involving Rana Kapoor as the stock prices decline dramatically during that period.**\n",
        "*   **After loading the dataset, we found that there are no null values in our dataset nor any duplicate data.**\n",
        "*   **There are some outliers in our features however this being a very small dataset, dropping those instances will lead to loss of information.**\n",
        "*   **We found that the distribution of all our variables is positively skewed. so we performed log transformation on them.**\n",
        "*   **There is a high correlation between the dependent and independent variables. This is a signal that our dependent variable is highly dependent on our features and can be predicted accurately from them.**\n",
        "*   **We found that there is a rather high correlation between our independent variables. This multicollinearity is however unavoidable here as the dataset is very small.**\n",
        "*   **We implemented several models on our dataset in order to be able to predict the closing price and found that all our models are performing remarkably well and *Elastic Net regressor is the best performing model with Adjusted R2 score value of 0.9932* and scores well on all evaluation metrics.** \n",
        "*   **All of the implemented models performed quite well on our data giving us the Adjusted R-square of over 99%.**\n",
        "*   **We checked for presence of Heterodasceticity in our dataset by plotting the residuals against the Elastic Net model predicted value and found that there is no Heterodasceticity present. Our model is performing well on all data-points.**\n",
        "*   **With our model making predictions with such high accuracy, we can confidently deploy this model for further predictive tasks using future data.** \n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}